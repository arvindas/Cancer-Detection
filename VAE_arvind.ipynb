{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzDEZJFsKlYt",
        "colab_type": "code",
        "outputId": "96ed3807-68db-4b37-f831-4c29968eba9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "! git clone --recursive https://github.com/shreyavarshini/Cancer-Detection.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Cancer-Detection'...\n",
            "remote: Enumerating objects: 18689, done.\u001b[K\n",
            "remote: Total 18689 (delta 0), reused 0 (delta 0), pack-reused 18689\u001b[K\n",
            "Receiving objects: 100% (18689/18689), 318.63 MiB | 36.22 MiB/s, done.\n",
            "Checking out files: 100% (18677/18677), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f9TYHoRU4u6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports and initializations\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms, transforms, utils\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKW7TOCicfrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cd '/content/Cancer-Detection/data/train/benign/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdFEC4zCENrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arguments for the model\n",
        "class Args:\n",
        "  batch_size = 20\n",
        "  epochs = 20\n",
        "  no_cuda = False\n",
        "  seed = 1\n",
        "  log_interval = 10\n",
        "  lr = 1e-3\n",
        "\n",
        "args=Args()\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "torch.manual_seed(args.seed)\n",
        "device = torch.device(\"cuda\" if args.cuda else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qXazX4SVDoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset loader\n",
        "def load_dataset( folder ):\n",
        "    data_path = '/content/Cancer-Detection/data/' + folder\n",
        "    transform = transforms.Compose([\n",
        "    transforms.Resize(( 256, 256 ) ),\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "    dataset = datasets.ImageFolder( root=data_path, transform=transform )\n",
        "\n",
        "    loader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=20,\n",
        "        num_workers=3,\n",
        "        shuffle=True\n",
        "    )\n",
        "    return loader\n",
        "\n",
        "train_loader = load_dataset( 'train' )\n",
        "test_loader = load_dataset( 'test' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW-VpJ-wJd7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, nc, ngf, ndf, latent_variable_size):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.nc = nc\n",
        "        self.ngf = ngf\n",
        "        self.ndf = ndf\n",
        "        self.latent_variable_size = latent_variable_size\n",
        "\n",
        "        # encoder\n",
        "        self.e1 = nn.Conv2d(nc, ndf, 4, 2, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(ndf)\n",
        "\n",
        "        self.e2 = nn.Conv2d(ndf, ndf*2, 4, 2, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(ndf*2)\n",
        "\n",
        "        self.e3 = nn.Conv2d(ndf*2, ndf*4, 4, 2, 1)\n",
        "        self.bn3 = nn.BatchNorm2d(ndf*4)\n",
        "\n",
        "        self.e4 = nn.Conv2d(ndf*4, ndf*4, 4, 2, 1)\n",
        "        self.bn4 = nn.BatchNorm2d(ndf*4)\n",
        "\n",
        "        # changed 12 = 4\n",
        "        self.e5 = nn.Conv2d(ndf*4, ndf*4, 12, 2, 1)\n",
        "        self.bn5 = nn.BatchNorm2d(ndf*4)\n",
        "\n",
        "        self.e6 = nn.Conv2d( ndf*8, ndf*8, 4, 2, 1)\n",
        "        self.bn6 = nn.BatchNorm2d(ndf*8)\n",
        "\n",
        "        #changed  8 = 4\n",
        "        self.fc1 = nn.Linear(ndf*4*4*4, latent_variable_size)\n",
        "        self.fc2 = nn.Linear(ndf*4*4*4, latent_variable_size)\n",
        "\n",
        "        # decoder\n",
        "        #changed 4 = 8\n",
        "        self.d1 = nn.Linear(latent_variable_size, ngf*4*2*4*4)\n",
        "\n",
        "        self.up1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "        self.pd1 = nn.ReplicationPad2d(1)\n",
        "        #changed 4 = 8\n",
        "        self.d2 = nn.Conv2d(ngf*4*2, ngf*4, 3, 1)\n",
        "        self.bn6 = nn.BatchNorm2d(ngf*4, 1.e-3)\n",
        "\n",
        "        self.up2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "        self.pd2 = nn.ReplicationPad2d(1)\n",
        "        #changed 4 = 8, 2 = 4\n",
        "        self.d3 = nn.Conv2d(ngf*4, ngf*2, 3, 1)\n",
        "        self.bn7 = nn.BatchNorm2d(ngf*2, 1.e-3)\n",
        "\n",
        "        self.up3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "        self.pd3 = nn.ReplicationPad2d(1)\n",
        "        # changed 4 = 2, none = 2\n",
        "        self.d4 = nn.Conv2d(ngf*2, ngf, 3, 1)\n",
        "        self.bn8 = nn.BatchNorm2d(ngf, 1.e-3)\n",
        "        # 5, 256, 32, 32\n",
        "\n",
        "        self.up4 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "        self.pd4 = nn.ReplicationPad2d(1)\n",
        "        #changed ngf = ngf * 2\n",
        "        self.d5 = nn.Conv2d(ngf, ngf, 3, 1)\n",
        "        self.bn9 = nn.BatchNorm2d(ngf, 1.e-3)\n",
        "        # 5, 256, 64, 64\n",
        "\n",
        "        self.up6 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "        self.pd6 = nn.ReplicationPad2d(1)\n",
        "        self.d7 = nn.Conv2d(ngf, ngf, 3, 1)\n",
        "        self.bn10 = nn.BatchNorm2d(ngf, 1.e-3)\n",
        "        # 5, 256, 128, 128\n",
        "\n",
        "        self.up5 = nn.UpsamplingNearest2d(scale_factor=2)\n",
        "        self.pd5 = nn.ReplicationPad2d(1)\n",
        "        self.d6 = nn.Conv2d(ngf, nc, 3, 1)\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = self.leakyrelu(self.bn1(self.e1(x)))\n",
        "        h2 = self.leakyrelu(self.bn2(self.e2(h1)))\n",
        "        h3 = self.leakyrelu(self.bn3(self.e3(h2)))\n",
        "        h4 = self.leakyrelu(self.bn4(self.e4(h3)))\n",
        "        h5 = self.leakyrelu(self.bn5(self.e5(h4)))\n",
        "        #h6 = self.leakyrelu(self.bn6(self.e6(h5)))\n",
        "        #changed 4 = 8\n",
        "        h6 = h5.view(-1, self.ndf*4*4*4)\n",
        "\n",
        "        return self.fc1(h6), self.fc2(h6)\n",
        "\n",
        "    def reparametrize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        if args.cuda:\n",
        "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
        "        else:\n",
        "            eps = torch.FloatTensor(std.size()).normal_()\n",
        "        eps = Variable(eps)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "    def decode(self, z):\n",
        "        h1 = self.relu(self.d1(z))\n",
        "        #changed 4 = 8\n",
        "        h1 = h1.view(-1, self.ngf*4*2, 4, 4)\n",
        "        h2 = self.leakyrelu(self.bn6(self.d2(self.pd1(self.up1(h1)))))\n",
        "        h3 = self.leakyrelu(self.bn7(self.d3(self.pd2(self.up2(h2)))))\n",
        "        h4 = self.leakyrelu(self.bn8(self.d4(self.pd3(self.up3(h3)))))\n",
        "        h5 = self.leakyrelu(self.bn9(self.d5(self.pd4(self.up4(h4)))))\n",
        "        h6 = self.leakyrelu(self.bn10(self.d7(self.pd6(self.up6(h5)))))\n",
        "        #changed h6 = h5\n",
        "        return self.sigmoid(self.d6(self.pd5(self.up5(h6))))\n",
        "\n",
        "    def get_latent_var(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
        "        z = self.reparametrize(mu, logvar)\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
        "        z = self.reparametrize(mu, logvar)\n",
        "        res = self.decode(z)\n",
        "        return res, mu, logvar\n",
        "\n",
        "\n",
        "model = VAE(nc=3, ngf=256, ndf=256, latent_variable_size=500)\n",
        "\n",
        "if args.cuda:\n",
        "    model.cuda()\n",
        "\n",
        "reconstruction_function = nn.BCELoss()\n",
        "reconstruction_function.size_average = False\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = reconstruction_function(recon_x, x)\n",
        "\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
        "\n",
        "    return BCE + KLD\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73qiGwhKETkL",
        "colab_type": "code",
        "outputId": "d94e0ec1-68cf-4246-846d-c1dca5c4ab51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = Variable(data)\n",
        "        data = data.to(device)\n",
        "        # update the gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        #print(recon_batch.shape)\n",
        "\n",
        "        # reconstruction loss + kl divergence loss\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        \n",
        "         # backward pass\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # update the weights\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    # set the evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # test loss for the data\n",
        "    test_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = Variable(data)\n",
        "            data = data.to(device)\n",
        "\n",
        "            # forward pass\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "\n",
        "            # total loss\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train(epoch)\n",
        "        test(epoch)\n",
        "        with torch.no_grad():\n",
        "            sample = torch.randn(1, 500).to(device)\n",
        "            sample = Variable(sample, volatile=True)\n",
        "            sample = model.decode(sample).cpu()\n",
        "            img = sample.view( 256, 256, 3 ).data\n",
        "            plt.figure()\n",
        "            plt.imshow(img )\n",
        "            plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[0.4667, 0.4157, 0.3843,  ..., 0.1137, 0.1059, 0.0941],\n",
            "          [0.4745, 0.4235, 0.4000,  ..., 0.1686, 0.1333, 0.1059],\n",
            "          [0.4902, 0.4392, 0.4196,  ..., 0.2039, 0.1569, 0.1176],\n",
            "          ...,\n",
            "          [0.4549, 0.4549, 0.4431,  ..., 0.0549, 0.0667, 0.0784],\n",
            "          [0.4902, 0.4980, 0.5059,  ..., 0.0667, 0.0784, 0.0902],\n",
            "          [0.5569, 0.5490, 0.5490,  ..., 0.1255, 0.1333, 0.1255]],\n",
            "\n",
            "         [[0.4667, 0.4157, 0.3843,  ..., 0.1137, 0.1059, 0.0941],\n",
            "          [0.4745, 0.4235, 0.4000,  ..., 0.1686, 0.1333, 0.1059],\n",
            "          [0.4902, 0.4392, 0.4196,  ..., 0.2039, 0.1569, 0.1176],\n",
            "          ...,\n",
            "          [0.4549, 0.4549, 0.4431,  ..., 0.0549, 0.0667, 0.0784],\n",
            "          [0.4902, 0.4980, 0.5059,  ..., 0.0667, 0.0784, 0.0902],\n",
            "          [0.5569, 0.5490, 0.5490,  ..., 0.1255, 0.1333, 0.1255]],\n",
            "\n",
            "         [[0.4667, 0.4157, 0.3843,  ..., 0.1137, 0.1059, 0.0941],\n",
            "          [0.4745, 0.4235, 0.4000,  ..., 0.1686, 0.1333, 0.1059],\n",
            "          [0.4902, 0.4392, 0.4196,  ..., 0.2039, 0.1569, 0.1176],\n",
            "          ...,\n",
            "          [0.4549, 0.4549, 0.4431,  ..., 0.0549, 0.0667, 0.0784],\n",
            "          [0.4902, 0.4980, 0.5059,  ..., 0.0667, 0.0784, 0.0902],\n",
            "          [0.5569, 0.5490, 0.5490,  ..., 0.1255, 0.1333, 0.1255]]],\n",
            "\n",
            "\n",
            "        [[[0.1765, 0.1686, 0.1686,  ..., 0.2863, 0.2784, 0.2745],\n",
            "          [0.1882, 0.1765, 0.1686,  ..., 0.2000, 0.2000, 0.2000],\n",
            "          [0.2000, 0.1725, 0.1490,  ..., 0.0627, 0.0784, 0.0863],\n",
            "          ...,\n",
            "          [0.4196, 0.3294, 0.2941,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.4157, 0.3490, 0.3216,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.4314, 0.3725, 0.3490,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.1765, 0.1686, 0.1686,  ..., 0.2863, 0.2784, 0.2745],\n",
            "          [0.1882, 0.1765, 0.1686,  ..., 0.2000, 0.2000, 0.2000],\n",
            "          [0.2000, 0.1725, 0.1490,  ..., 0.0627, 0.0784, 0.0863],\n",
            "          ...,\n",
            "          [0.4196, 0.3294, 0.2941,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.4157, 0.3490, 0.3216,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.4314, 0.3725, 0.3490,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.1765, 0.1686, 0.1686,  ..., 0.2863, 0.2784, 0.2745],\n",
            "          [0.1882, 0.1765, 0.1686,  ..., 0.2000, 0.2000, 0.2000],\n",
            "          [0.2000, 0.1725, 0.1490,  ..., 0.0627, 0.0784, 0.0863],\n",
            "          ...,\n",
            "          [0.4196, 0.3294, 0.2941,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.4157, 0.3490, 0.3216,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.4314, 0.3725, 0.3490,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0039, 0.0196,  ..., 0.0235, 0.0196, 0.0157],\n",
            "          [0.0039, 0.0000, 0.0118,  ..., 0.0235, 0.0196, 0.0157],\n",
            "          [0.0078, 0.0000, 0.0118,  ..., 0.0392, 0.0314, 0.0275]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0039, 0.0196,  ..., 0.0235, 0.0196, 0.0157],\n",
            "          [0.0039, 0.0000, 0.0118,  ..., 0.0235, 0.0196, 0.0157],\n",
            "          [0.0078, 0.0000, 0.0118,  ..., 0.0392, 0.0314, 0.0275]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0039, 0.0196,  ..., 0.0235, 0.0196, 0.0157],\n",
            "          [0.0039, 0.0000, 0.0118,  ..., 0.0235, 0.0196, 0.0157],\n",
            "          [0.0078, 0.0000, 0.0118,  ..., 0.0392, 0.0314, 0.0275]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.0314, 0.0314, 0.0314,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0235, 0.0235, 0.0235],\n",
            "          ...,\n",
            "          [0.0275, 0.0275, 0.0235,  ..., 0.0078, 0.0196, 0.0353],\n",
            "          [0.0314, 0.0275, 0.0275,  ..., 0.0039, 0.0196, 0.0314],\n",
            "          [0.0314, 0.0314, 0.0275,  ..., 0.0039, 0.0157, 0.0314]],\n",
            "\n",
            "         [[0.0314, 0.0314, 0.0314,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0235, 0.0235, 0.0235],\n",
            "          ...,\n",
            "          [0.0275, 0.0275, 0.0235,  ..., 0.0078, 0.0196, 0.0353],\n",
            "          [0.0314, 0.0275, 0.0275,  ..., 0.0039, 0.0196, 0.0314],\n",
            "          [0.0314, 0.0314, 0.0275,  ..., 0.0039, 0.0157, 0.0314]],\n",
            "\n",
            "         [[0.0314, 0.0314, 0.0314,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0314, 0.0314, 0.0314,  ..., 0.0235, 0.0235, 0.0235],\n",
            "          ...,\n",
            "          [0.0275, 0.0275, 0.0235,  ..., 0.0078, 0.0196, 0.0353],\n",
            "          [0.0314, 0.0275, 0.0275,  ..., 0.0039, 0.0196, 0.0314],\n",
            "          [0.0314, 0.0314, 0.0275,  ..., 0.0039, 0.0157, 0.0314]]],\n",
            "\n",
            "\n",
            "        [[[0.0118, 0.0078, 0.0039,  ..., 0.0941, 0.0941, 0.0980],\n",
            "          [0.0118, 0.0078, 0.0039,  ..., 0.0941, 0.0941, 0.0980],\n",
            "          [0.0118, 0.0078, 0.0039,  ..., 0.0941, 0.0941, 0.0980],\n",
            "          ...,\n",
            "          [0.0353, 0.0314, 0.0275,  ..., 0.1765, 0.2000, 0.2235],\n",
            "          [0.0353, 0.0314, 0.0275,  ..., 0.1647, 0.1922, 0.2196],\n",
            "          [0.0353, 0.0314, 0.0275,  ..., 0.1569, 0.1804, 0.2118]],\n",
            "\n",
            "         [[0.0118, 0.0078, 0.0039,  ..., 0.0941, 0.0941, 0.0980],\n",
            "          [0.0118, 0.0078, 0.0039,  ..., 0.0941, 0.0941, 0.0980],\n",
            "          [0.0118, 0.0078, 0.0039,  ..., 0.0941, 0.0941, 0.0980],\n",
            "          ...,\n",
            "          [0.0353, 0.0314, 0.0275,  ..., 0.1765, 0.2000, 0.2235],\n",
            "          [0.0353, 0.0314, 0.0275,  ..., 0.1647, 0.1922, 0.2196],\n",
            "          [0.0353, 0.0314, 0.0275,  ..., 0.1569, 0.1804, 0.2118]],\n",
            "\n",
            "         [[0.0118, 0.0078, 0.0039,  ..., 0.0941, 0.0941, 0.0980],\n",
            "          [0.0118, 0.0078, 0.0039,  ..., 0.0941, 0.0941, 0.0980],\n",
            "          [0.0118, 0.0078, 0.0039,  ..., 0.0941, 0.0941, 0.0980],\n",
            "          ...,\n",
            "          [0.0353, 0.0314, 0.0275,  ..., 0.1765, 0.2000, 0.2235],\n",
            "          [0.0353, 0.0314, 0.0275,  ..., 0.1647, 0.1922, 0.2196],\n",
            "          [0.0353, 0.0314, 0.0275,  ..., 0.1569, 0.1804, 0.2118]]],\n",
            "\n",
            "\n",
            "        [[[0.1882, 0.1412, 0.1333,  ..., 0.1255, 0.1490, 0.1882],\n",
            "          [0.1725, 0.1255, 0.1216,  ..., 0.1137, 0.1373, 0.1765],\n",
            "          [0.1608, 0.1137, 0.1098,  ..., 0.1020, 0.1216, 0.1647],\n",
            "          ...,\n",
            "          [0.9843, 0.8627, 0.5490,  ..., 0.3098, 0.5451, 0.8863],\n",
            "          [0.9882, 0.9843, 0.8667,  ..., 0.7569, 0.9020, 0.9882],\n",
            "          [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9843, 0.9922]],\n",
            "\n",
            "         [[0.1882, 0.1412, 0.1333,  ..., 0.1255, 0.1490, 0.1882],\n",
            "          [0.1725, 0.1255, 0.1216,  ..., 0.1137, 0.1373, 0.1765],\n",
            "          [0.1608, 0.1137, 0.1098,  ..., 0.1020, 0.1216, 0.1647],\n",
            "          ...,\n",
            "          [0.9843, 0.8627, 0.5490,  ..., 0.3098, 0.5451, 0.8863],\n",
            "          [0.9882, 0.9843, 0.8667,  ..., 0.7569, 0.9020, 0.9882],\n",
            "          [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9843, 0.9922]],\n",
            "\n",
            "         [[0.1882, 0.1412, 0.1333,  ..., 0.1255, 0.1490, 0.1882],\n",
            "          [0.1725, 0.1255, 0.1216,  ..., 0.1137, 0.1373, 0.1765],\n",
            "          [0.1608, 0.1137, 0.1098,  ..., 0.1020, 0.1216, 0.1647],\n",
            "          ...,\n",
            "          [0.9843, 0.8627, 0.5490,  ..., 0.3098, 0.5451, 0.8863],\n",
            "          [0.9882, 0.9843, 0.8667,  ..., 0.7569, 0.9020, 0.9882],\n",
            "          [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9843, 0.9922]]]])\n",
            "> <ipython-input-7-d8e8d0abf1e9>(11)train()\n",
            "-> data = data.to(device)\n",
            "--KeyboardInterrupt--\n",
            "--KeyboardInterrupt--\n",
            "--KeyboardInterrupt--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGDxMnLxMqYM",
        "colab_type": "code",
        "outputId": "9d515ef3-089c-427d-9e88-fe237a3fc2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "!ps -aux|grep python"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root          18  0.4  0.7 402900 98776 ?        Sl   15:19   0:02 /usr/bin/python2 /usr/local/bin/jupyter-notebook --ip=\"172.28.0.2\" --port=9000 --FileContentsManager.root_dir=\"/\" --MappingKernelManager.root_dir=\"/content\"\n",
            "root         121  7.6 23.3 42509664 3111508 ?    Ssl  15:23   0:12 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-ea850a1b-b975-4d9c-a93f-20e5ff53e863.json\n",
            "root         239  0.0  0.0  39196  6568 ?        S    15:26   0:00 /bin/bash -c ps -aux|grep python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L7hCW0iMw3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 121"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}